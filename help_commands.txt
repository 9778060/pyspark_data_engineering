//---------------------------
docker
//---------------------------

start container:
docker compose up

stop container:
docker compose down

list active components in docker:
docker ps

enter into hdfs:
docker exec -it hdfs-namenode bash

enter into spark:
docker exec -it spark-master spark-shell

enter into spark pyspark:
docker exec -it jupyter-notebook pyspark
docker exec -it spark-master pyspark

enter into spark bash:
docker exec -it jupyter-notebook bash
docker exec -it spark-master bash

//---------------------------
hdfs
//---------------------------

list:
hdfs dfs -ls /

create folder:
hdfs dfs -mkdir -p /input

dump file from local to hdfs:
hdfs dfs -put test.txt /input


//---------------------------
bash
//---------------------------

top 10 rows of the files with the mask part*:
head -10 part*

bottom 10 rows of the files with the mask part*:
tail -10 part*

//---------------------------
jupyter
//---------------------------
jupyter nbconvert --to script test.ipynb


//---------------------------
spark bash
//---------------------------
spark-submit test.py