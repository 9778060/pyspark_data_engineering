//---------------------------
spark
//---------------------------

read csv into df:
df = spark.read.csv("/opt/spark-apps/input/customers.csv", header=True)
df = spark.read.option("header", True).csv("/opt/spark-apps/input/customers.csv")

read json into df:
df = spark.read.json("/opt/spark-apps/input/orders.json")

read parquet into df:
df_output_parquet = spark.read.parquet("hdfs://hdfs-namenode:9000/sales_etl/output/final_parquet/part*")

show df:
df.show()
df.show(5, False)

print schema:
df.printSchema()

write df into csv:
df_output.write.mode("overwrite").option("header", True).csv("hdfs://hdfs-namenode:9000/sales_etl/output/final_csv")

write df into parquet:
df_output.write.mode("overwrite").parquet("hdfs://hdfs-namenode:9000/sales_etl/output/final_parquet")
