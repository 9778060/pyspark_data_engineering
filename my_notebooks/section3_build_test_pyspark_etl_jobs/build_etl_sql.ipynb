{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd13228-fe65-47ff-9193-31f4f9b0d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CustomerOrdersJobSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8730c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_path = \"/opt/spark-apps/input/customers.csv\"\n",
    "orders_path = \"/opt/spark-apps/input/orders.json\"\n",
    "output_path_csv = \"/opt/spark-apps/output/orders_enriched_csv\"\n",
    "output_path_parquet = \"/opt/spark-apps/output/orders_enriched_parquet\"\n",
    "\n",
    "# âœ… Prod Mode (HDFS)\n",
    "# customers_path = \"hdfs://hdfs-namenode:9000/input/customers.csv\"\n",
    "# orders_path = \"hdfs://hdfs-namenode:9000/input/orders.json\"\n",
    "# output_path_csv = \"hdfs://hdfs-namenode:9000/output/orders_enriched_csv\"\n",
    "# output_path_parquet = \"hdfs://hdfs-namenode:9000/output/orders_enriched_parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5149b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = spark.read.option(\"header\", True).csv(customers_path)\n",
    "df_orders = spark.read.json(orders_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5ca96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.createOrReplaceTempView(\"customers\")\n",
    "df_orders.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de4ca9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------------+---+-------+\n",
      "|customer_id|      name|           email|age|country|\n",
      "+-----------+----------+----------------+---+-------+\n",
      "|        101|  John Doe|john@example.com| 28|     US|\n",
      "|        102|Jane Smith|jane@example.com| 34|     UK|\n",
      "|        103|  Ali Khan| ali@example.com| 40|    UAE|\n",
      "|        104|Rita Mehra|rita@example.com| 25|  India|\n",
      "|        105| Wei Zhang| wei@example.com| 31|  China|\n",
      "+-----------+----------+----------------+---+-------+\n",
      "\n",
      "+------+-----------+--------+----------+\n",
      "|amount|customer_id|order_id|    status|\n",
      "+------+-----------+--------+----------+\n",
      "| 250.5|        101|    5001|   shipped|\n",
      "| 145.0|        102|    5002| cancelled|\n",
      "|389.99|        104|    5003|processing|\n",
      "| 89.99|        105|    5004|   shipped|\n",
      "| 199.0|        106|    5005|  returned|\n",
      "+------+-----------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.show(), df_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b8a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------------+---+-------+\n",
      "|customer_id|    name|           email|age|country|\n",
      "+-----------+--------+----------------+---+-------+\n",
      "|        101|John Doe|john@example.com| 28|     US|\n",
      "+-----------+--------+----------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM customers\n",
    "    WHERE country = 'US'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c4a617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+------------+\n",
      "|order_id|      name|amount|  order_type|\n",
      "+--------+----------+------+------------+\n",
      "|    5001|  John Doe| 250.5|  High Value|\n",
      "|    5002|Jane Smith| 145.0|Medium Value|\n",
      "|    5003|Rita Mehra|389.99|  High Value|\n",
      "|    5004| Wei Zhang| 89.99|   Low Value|\n",
      "+--------+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT o.order_id, c.name, o.amount,\n",
    "           CASE \n",
    "               WHEN o.amount >= 200 THEN 'High Value'\n",
    "               WHEN o.amount >= 100 THEN 'Medium Value'\n",
    "               ELSE 'Low Value'\n",
    "           END AS order_type\n",
    "    FROM orders o\n",
    "    JOIN customers c\n",
    "      ON o.customer_id = c.customer_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6359941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_op = spark.sql(\"\"\"\n",
    "    SELECT o.order_id, c.name, o.amount,\n",
    "           CASE \n",
    "               WHEN o.amount >= 200 THEN 'High Value'\n",
    "               WHEN o.amount >= 100 THEN 'Medium Value'\n",
    "               ELSE 'Low Value'\n",
    "           END AS order_type\n",
    "    FROM orders o\n",
    "    JOIN customers c\n",
    "      ON o.customer_id = c.customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961216fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched_op.write.mode(\"overwrite\").csv(output_path_csv)\n",
    "df_enriched_op.write.mode(\"overwrite\").parquet(output_path_parquet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
