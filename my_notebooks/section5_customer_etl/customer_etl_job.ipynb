{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c649d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CustomerETL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635a2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = spark.read.option(\"header\", True).csv(\"hdfs://hdfs-namenode:9000/customer_etl/input/orders.csv\")\n",
    "df_products = spark.read.json(\"hdfs://hdfs-namenode:9000/customer_etl/input/products.json\")\n",
    "df_customers = spark.read.option(\"header\", True).csv(\"hdfs://hdfs-namenode:9000/customer_etl/input/customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34052dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.createOrReplaceTempView(\"orders\")\n",
    "df_products.createOrReplaceTempView(\"products\")\n",
    "df_customers.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83164ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------+----------+\n",
      "|order_id|customer_id|product_id|quantity|order_date|\n",
      "+--------+-----------+----------+--------+----------+\n",
      "|    O001|       C101|      P201|       1|2025-05-01|\n",
      "|    O002|       C101|      P202|       2|2025-05-02|\n",
      "|    O003|       C102|      P201|       1|2025-05-02|\n",
      "|    O004|       C101|      P203|       2|2025-05-03|\n",
      "|    O005|       C103|      P204|       1|2025-05-05|\n",
      "|    O006|       C102|      P201|       2|2025-05-06|\n",
      "|    O007|       C101|      P202|       1|2025-05-07|\n",
      "|    O008|       C104|      P203|       2|2025-05-07|\n",
      "|    O009|       C104|      P202|       1|2025-05-08|\n",
      "|    O010|       C105|      P201|       1|2025-05-08|\n",
      "+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM orders o\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a898a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------+----------+\n",
      "|_corrupt_record|   category|product_id|unit_price|\n",
      "+---------------+-----------+----------+----------+\n",
      "|              [|       null|      null|      null|\n",
      "|           null|      Books|      P201|       250|\n",
      "|           null|Electronics|      P202|      1200|\n",
      "|           null|     Health|      P203|       400|\n",
      "|           null| Stationery|      P204|       150|\n",
      "|              ]|       null|      null|      null|\n",
      "+---------------+-----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM products\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3b295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+-----+-----------+\n",
      "|customer_id|  customer_name|         city|state|signup_date|\n",
      "+-----------+---------------+-------------+-----+-----------+\n",
      "|       C101|Olivia Thompson|      Seattle|   WA| 2024-10-15|\n",
      "|       C102|  Ethan Johnson|       Austin|   TX| 2025-01-05|\n",
      "|       C103|     Emma Davis|     New York|   NY| 2025-03-20|\n",
      "|       C104|    Liam Garcia|      Chicago|   IL| 2025-01-25|\n",
      "|       C105|   Ava Martinez|San Francisco|   CA| 2025-02-10|\n",
      "+-----------+---------------+-------------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM customers\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1b66b",
   "metadata": {},
   "source": [
    "## Step 2: Enrich + Aggregate + Classify (Using SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b7716a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enrich with price\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW enriched_orders AS\n",
    "    SELECT\n",
    "        o.order_id,\n",
    "        o.customer_id,\n",
    "        o.product_id,\n",
    "        o.quantity,\n",
    "        o.order_date,\n",
    "        p.category,\n",
    "        p.unit_price,\n",
    "        o.quantity * p.unit_price AS total_price\n",
    "    FROM orders o\n",
    "    JOIN products p ON o.product_id = p.product_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2924508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+--------+----------+-----------+----------+-----------+\n",
      "|order_id|customer_id|product_id|quantity|order_date|   category|unit_price|total_price|\n",
      "+--------+-----------+----------+--------+----------+-----------+----------+-----------+\n",
      "|    O001|       C101|      P201|       1|2025-05-01|      Books|       250|      250.0|\n",
      "|    O002|       C101|      P202|       2|2025-05-02|Electronics|      1200|     2400.0|\n",
      "|    O003|       C102|      P201|       1|2025-05-02|      Books|       250|      250.0|\n",
      "|    O004|       C101|      P203|       2|2025-05-03|     Health|       400|      800.0|\n",
      "|    O005|       C103|      P204|       1|2025-05-05| Stationery|       150|      150.0|\n",
      "|    O006|       C102|      P201|       2|2025-05-06|      Books|       250|      500.0|\n",
      "|    O007|       C101|      P202|       1|2025-05-07|Electronics|      1200|     1200.0|\n",
      "|    O008|       C104|      P203|       2|2025-05-07|     Health|       400|      800.0|\n",
      "|    O009|       C104|      P202|       1|2025-05-08|Electronics|      1200|     1200.0|\n",
      "|    O010|       C105|      P201|       1|2025-05-08|      Books|       250|      250.0|\n",
      "+--------+-----------+----------+--------+----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM enriched_orders\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2f56fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate per customer\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW customer_metrics AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        COUNT(order_id) AS total_orders,\n",
    "        SUM(total_price) AS total_spent,\n",
    "        COUNT(DISTINCT order_date) AS days_active,\n",
    "        COUNT(DISTINCT category) AS categories_bought\n",
    "    FROM enriched_orders\n",
    "    GROUP BY customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb03e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+-----------+-----------------+\n",
      "|customer_id|total_orders|total_spent|days_active|categories_bought|\n",
      "+-----------+------------+-----------+-----------+-----------------+\n",
      "|       C104|           2|     2000.0|          2|                2|\n",
      "|       C102|           2|      750.0|          2|                1|\n",
      "|       C103|           1|      150.0|          1|                1|\n",
      "|       C105|           1|      250.0|          1|                1|\n",
      "|       C101|           4|     4650.0|          4|                3|\n",
      "+-----------+------------+-----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM customer_metrics\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1e2424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add loyalty label\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW customer_loyalty AS\n",
    "    SELECT\n",
    "        m.customer_id,\n",
    "        c.customer_name,\n",
    "        c.city,\n",
    "        c.state,\n",
    "        c.signup_date,\n",
    "        m.total_orders,\n",
    "        m.total_spent,\n",
    "        m.days_active,\n",
    "        m.categories_bought,\n",
    "        CASE\n",
    "            WHEN m.total_orders >= 3 AND m.days_active >= 2 AND m.categories_bought >= 2 THEN 'Loyal'\n",
    "            WHEN m.total_orders >= 2 AND (m.days_active >= 2 OR m.categories_bought >= 2) THEN 'Engaged'\n",
    "            ELSE 'Casual'\n",
    "        END AS loyalty_status\n",
    "    FROM customer_metrics m\n",
    "    JOIN customers c ON m.customer_id = c.customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18db47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "|customer_id|  customer_name|         city|state|signup_date|total_orders|total_spent|days_active|categories_bought|loyalty_status|\n",
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "|       C104|    Liam Garcia|      Chicago|   IL| 2025-01-25|           2|     2000.0|          2|                2|       Engaged|\n",
      "|       C102|  Ethan Johnson|       Austin|   TX| 2025-01-05|           2|      750.0|          2|                1|       Engaged|\n",
      "|       C103|     Emma Davis|     New York|   NY| 2025-03-20|           1|      150.0|          1|                1|        Casual|\n",
      "|       C105|   Ava Martinez|San Francisco|   CA| 2025-02-10|           1|      250.0|          1|                1|        Casual|\n",
      "|       C101|Olivia Thompson|      Seattle|   WA| 2024-10-15|           4|     4650.0|          4|                3|         Loyal|\n",
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM customer_loyalty\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fa178",
   "metadata": {},
   "source": [
    "## Step 3: Write Final Output to HDFS (Parquet only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "992b1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty = spark.sql(\"SELECT * FROM customer_loyalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0fe7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "|customer_id|  customer_name|         city|state|signup_date|total_orders|total_spent|days_active|categories_bought|loyalty_status|\n",
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "|       C104|    Liam Garcia|      Chicago|   IL| 2025-01-25|           2|     2000.0|          2|                2|       Engaged|\n",
      "|       C102|  Ethan Johnson|       Austin|   TX| 2025-01-05|           2|      750.0|          2|                1|       Engaged|\n",
      "|       C103|     Emma Davis|     New York|   NY| 2025-03-20|           1|      150.0|          1|                1|        Casual|\n",
      "|       C105|   Ava Martinez|San Francisco|   CA| 2025-02-10|           1|      250.0|          1|                1|        Casual|\n",
      "|       C101|Olivia Thompson|      Seattle|   WA| 2024-10-15|           4|     4650.0|          4|                3|         Loyal|\n",
      "+-----------+---------------+-------------+-----+-----------+------------+-----------+-----------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_loyalty.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty.write.mode(\"overwrite\").option(\"header\", True).csv(\"hdfs://hdfs-namenode:9000/customer_etl/output/loyalty_snapshot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
